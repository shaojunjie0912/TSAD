#!/usr/bin/env python3
"""
Optuna è°ƒä¼˜ç»“æœå¯è§†åŒ–å·¥å…·

ä½¿ç”¨æ–¹æ³•:
python ts_benchmark/visualize_optuna.py --study-db path/to/study.db --study-name study_name
"""

import argparse
import os
from typing import Any, Dict

import optuna

try:
    import optuna.visualization as vis
    import plotly.graph_objects as go

    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("âŒ ç¼ºå°‘ä¾èµ–åŒ…ï¼Œè¯·å®‰è£…: pip install plotly")
    exit(1)


def generate_optimization_plots(
    study: optuna.Study, output_dir: str, study_info: Dict[str, Any]
) -> None:
    """ç”Ÿæˆä¼˜åŒ–è¿‡ç¨‹çš„å¯è§†åŒ–å›¾è¡¨"""
    if len(study.trials) == 0:
        print("âš ï¸ æ²¡æœ‰è¯•éªŒæ•°æ®ï¼Œè·³è¿‡å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆ")
        return

    os.makedirs(output_dir, exist_ok=True)

    # æ ¹æ®studyåç§°æ¨æ–­æŒ‡æ ‡ç±»å‹
    metric_name = "Affiliation-F" if "find_anomalies" in study_info.get("task", "") else "AUC-ROC"
    dataset_name = study_info.get("dataset", "Unknown")

    try:
        # 1. ä¼˜åŒ–å†å²å›¾
        print("ğŸ“Š ç”Ÿæˆä¼˜åŒ–å†å²å›¾...")
        fig_history = vis.plot_optimization_history(study)
        fig_history.update_layout(
            title=f"ä¼˜åŒ–å†å² - {dataset_name} ({metric_name})",
            xaxis_title="è¯•éªŒæ¬¡æ•°",
            yaxis_title=f"{metric_name} åˆ†æ•°",
        )
        fig_history.write_html(f"{output_dir}/optimization_history.html")

        # 2. å‚æ•°é‡è¦æ€§å›¾
        print("ğŸ“Š ç”Ÿæˆå‚æ•°é‡è¦æ€§å›¾...")
        fig_importance = vis.plot_param_importances(study)
        fig_importance.update_layout(title=f"å‚æ•°é‡è¦æ€§ - {dataset_name}", xaxis_title="é‡è¦æ€§")
        fig_importance.write_html(f"{output_dir}/param_importances.html")

        # 3. å‚æ•°å…³ç³»å›¾
        print("ğŸ“Š ç”Ÿæˆå‚æ•°å…³ç³»å›¾...")
        fig_slice = vis.plot_slice(study)
        fig_slice.update_layout(title=f"å‚æ•°åˆ‡ç‰‡åˆ†æ - {dataset_name}")
        fig_slice.write_html(f"{output_dir}/param_slice.html")

        # 4. å¹¶è¡Œåæ ‡å›¾
        print("ğŸ“Š ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾...")
        fig_parallel = vis.plot_parallel_coordinate(study)
        fig_parallel.update_layout(title=f"å¹¶è¡Œåæ ‡å›¾ - {dataset_name}")
        fig_parallel.write_html(f"{output_dir}/parallel_coordinate.html")

        # 5. æ”¶æ•›åˆ†æ
        print("ğŸ“Š ç”Ÿæˆæ”¶æ•›åˆ†æå›¾...")
        completed_trials = [
            t
            for t in study.trials
            if t.state == optuna.trial.TrialState.COMPLETE and t.value is not None
        ]
        if len(completed_trials) > 1:
            trial_numbers = [t.number for t in completed_trials]
            trial_values = [t.value for t in completed_trials if t.value is not None]

            # è®¡ç®—è¿è¡Œæœ€ä½³å€¼
            best_values = []
            current_best = float("-inf")
            for value in trial_values:
                if value > current_best:
                    current_best = value
                best_values.append(current_best)

            # åˆ›å»ºæ”¶æ•›å›¾
            fig_convergence = go.Figure()
            fig_convergence.add_trace(
                go.Scatter(
                    x=trial_numbers,
                    y=trial_values,
                    mode="markers",
                    name="è¯•éªŒç»“æœ",
                    marker=dict(color="lightblue", size=8),
                )
            )
            fig_convergence.add_trace(
                go.Scatter(
                    x=trial_numbers,
                    y=best_values,
                    mode="lines+markers",
                    name="æœ€ä½³å€¼è¶‹åŠ¿",
                    line=dict(color="red", width=2),
                )
            )
            fig_convergence.update_layout(
                title=f"æ”¶æ•›åˆ†æ - {dataset_name}",
                xaxis_title="è¯•éªŒæ¬¡æ•°",
                yaxis_title=f"{metric_name} åˆ†æ•°",
                hovermode="x unified",
            )
            fig_convergence.write_html(f"{output_dir}/convergence_analysis.html")

        print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir}")
        print(f"ğŸ“Š å¯åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ HTML æ–‡ä»¶æŸ¥çœ‹äº¤äº’å¼å›¾è¡¨")

    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨æ—¶å‡ºé”™: {e}")


def analyze_convergence(study: optuna.Study, window_size: int = 20) -> Dict[str, Any]:
    """åˆ†æä¼˜åŒ–æ”¶æ•›æƒ…å†µ"""
    completed_trials = [
        t
        for t in study.trials
        if t.state == optuna.trial.TrialState.COMPLETE and t.value is not None
    ]

    if len(completed_trials) < window_size:
        return {
            "is_converged": False,
            "reason": f"è¯•éªŒæ•°é‡ä¸è¶³ ({len(completed_trials)} < {window_size})",
            "improvement_rate": 0.0,
        }

    # è®¡ç®—æœ€è¿‘window_sizeä¸ªè¯•éªŒçš„æ”¹è¿›æƒ…å†µ
    recent_trials = completed_trials[-window_size:]
    recent_values = [t.value for t in recent_trials if t.value is not None]

    if not recent_values:
        return {"is_converged": False, "reason": "æ²¡æœ‰æœ‰æ•ˆçš„è¯•éªŒå€¼", "improvement_rate": 0.0}

    # è®¡ç®—æ”¹è¿›ç‡
    best_in_window = max(recent_values)
    all_values = [t.value for t in completed_trials if t.value is not None]
    best_overall = max(all_values) if all_values else 0.0
    improvement_rate = (
        (best_in_window - best_overall) / abs(best_overall) if best_overall != 0 else 0
    )

    # åˆ¤æ–­æ˜¯å¦æ”¶æ•›
    is_converged = abs(improvement_rate) < 0.001  # æ”¹è¿›ç‡å°äº0.1%è®¤ä¸ºæ”¶æ•›

    return {
        "is_converged": is_converged,
        "improvement_rate": improvement_rate,
        "recent_best": best_in_window,
        "overall_best": best_overall,
        "trials_analyzed": len(completed_trials),
    }


def parse_study_name(study_name: str) -> Dict[str, Any]:
    """ä»studyåç§°è§£æä¿¡æ¯"""
    parts = study_name.split("_")
    info = {}

    if len(parts) >= 4:
        info["task"] = parts[0]
        info["dataset"] = parts[1]
        info["algorithm"] = parts[2]

        # æŸ¥æ‰¾ratioéƒ¨åˆ†
        for i, part in enumerate(parts):
            if part == "ratio" and i + 1 < len(parts):
                info["ratio"] = parts[i + 1]
                break

    return info


def main():
    parser = argparse.ArgumentParser(description="Optuna è°ƒä¼˜ç»“æœå¯è§†åŒ–å·¥å…·")
    parser.add_argument("--study-db", type=str, required=True, help="Study æ•°æ®åº“è·¯å¾„")
    parser.add_argument("--study-name", type=str, required=True, help="Study åç§°")
    parser.add_argument("--output-dir", type=str, help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤åŸºäºstudyåç§°ç”Ÿæˆï¼‰")
    parser.add_argument("--window-size", type=int, default=20, help="æ”¶æ•›åˆ†æçª—å£å¤§å°")

    args = parser.parse_args()

    # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.study_db):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {args.study_db}")
        return

    # åŠ è½½study
    try:
        study = optuna.load_study(study_name=args.study_name, storage=f"sqlite:///{args.study_db}")
        print(f"âœ… æˆåŠŸåŠ è½½ study: {args.study_name}")
        print(f"ğŸ“Š è¯•éªŒæ€»æ•°: {len(study.trials)}")

        completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]
        print(f"âœ… å®Œæˆè¯•éªŒæ•°: {len(completed_trials)}")

        if len(completed_trials) > 0:
            try:
                best_trial = study.best_trial
                print(f"ğŸ† æœ€ä½³åˆ†æ•°: {best_trial.value:.4f} (Trial {best_trial.number})")
            except ValueError:
                print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„æœ€ä½³è¯•éªŒ")

    except Exception as e:
        print(f"âŒ åŠ è½½ study å¤±è´¥: {e}")
        return

    # ç”Ÿæˆè¾“å‡ºç›®å½•
    if args.output_dir:
        output_dir = args.output_dir
    else:
        study_info = parse_study_name(args.study_name)
        dataset = study_info.get("dataset", "unknown")
        algorithm = study_info.get("algorithm", "unknown")
        output_dir = f"optuna_visualizations/{dataset}/{algorithm}"

    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    study_info = parse_study_name(args.study_name)
    generate_optimization_plots(study, output_dir, study_info)

    # æ”¶æ•›åˆ†æ
    convergence_info = analyze_convergence(study, args.window_size)
    print(f"\nğŸ” æ”¶æ•›åˆ†æ:")
    print(f"  - æ˜¯å¦æ”¶æ•›: {'æ˜¯' if convergence_info['is_converged'] else 'å¦'}")
    if not convergence_info["is_converged"]:
        print(f"  - åŸå› : {convergence_info.get('reason', 'æ”¹è¿›ç‡è¿‡é«˜')}")
    print(f"  - æ”¹è¿›ç‡: {convergence_info['improvement_rate']:.4f}")
    print(f"  - åˆ†æè¯•éªŒæ•°: {convergence_info['trials_analyzed']}")


if __name__ == "__main__":
    main()
