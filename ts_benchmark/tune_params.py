import argparse
import copy
import os
from typing import Any, Dict

import numpy as np
import optuna
import pandas as pd
import tomli
import tomli_w
from baselines.swift.swift_pipeline import swift_find_anomalies
from evaluation.metrics.anomaly_detection_metrics_label import affiliation_f
from tools.tools import set_seed


def load_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½ TOML é…ç½®æ–‡ä»¶ã€‚"""
    with open(config_path, "rb") as f:
        return tomli.load(f)


def update_config(base_config: Dict[str, Any], param_updates: Dict[str, Any]) -> Dict[str, Any]:
    """æ ¹æ® Optuna æä¾›çš„å‚æ•°æ›´æ–°é…ç½®å­—å…¸ã€‚"""
    config = copy.deepcopy(base_config)
    for key_path, value in param_updates.items():
        keys = key_path.split(".")
        current = config
        for key in keys[:-1]:
            current = current.get(key, {})
        current[keys[-1]] = value
    return config


def save_optimal_config(base_config: Dict[str, Any], best_params: Dict[str, Any], output_path: str):
    """å°†ä¼˜åŒ–åçš„é…ç½®ä¿å­˜åˆ° TOML æ–‡ä»¶ã€‚"""
    if not best_params:
        print("ğŸŸ¡ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆå‚æ•°ï¼Œä¸ä¿å­˜é…ç½®æ–‡ä»¶ã€‚")
        return

    optimal_config = update_config(base_config, best_params)
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, "wb") as f:
        tomli_w.dump(optimal_config, f)
    print(f"ğŸ’¾ æ–°çš„æœ€ä½³é…ç½®å·²ä¿å­˜åˆ°: {output_path}")


# --------------------------------------------------------------------------- #
#                       Optuna æ ¸å¿ƒç›®æ ‡å‡½æ•° (Objective)                         #
# --------------------------------------------------------------------------- #


def objective(
    trial: optuna.trial.Trial, base_config: Dict[str, Any], data: np.ndarray, labels: np.ndarray
) -> float:
    param_updates = {}
    param_updates["trial_number"] = trial.number

    # ---- loss æŸå¤±å‡½æ•° ----
    param_updates["loss.ccd_loss_lambda"] = trial.suggest_float("loss.ccd_loss_lambda", 1e-4, 1e-1, log=True)
    param_updates["loss.scale_loss_lambda"] = trial.suggest_float("loss.scale_loss_lambda", 0.2, 1.0)
    param_updates["loss.ccd_regular_lambda"] = trial.suggest_float("loss.ccd_regular_lambda", 0.05, 0.5)
    param_updates["loss.ccd_align_lambda"] = trial.suggest_float("loss.ccd_align_lambda", 0.5, 2.0)

    # ---- model.FM å‰å‘æ¨¡å— ----
    param_updates["model.FM.level"] = trial.suggest_int("fm.level", 2, 5)

    # ---- model.CFM é€šé“èåˆæ¨¡å— ----
    param_updates["model.CFM.num_heads"] = trial.suggest_categorical("cfm.num_heads", [2, 4, 8])
    param_updates["model.CFM.attention_dropout"] = trial.suggest_float("cfm.attention_dropout", 0.05, 0.3)
    d_cf_val = trial.suggest_categorical("cfm.d_cf", [64, 96, 128])
    d_model_val = trial.suggest_categorical("cfm.d_model", [64, 96, 128])
    if d_model_val < d_cf_val:  # ä¸æ»¡è¶³çº¦æŸæ¡ä»¶ d_model >= d_cf åˆ™å‰ªæ
        raise optuna.TrialPruned()
    param_updates["model.CFM.d_cf"] = d_cf_val
    param_updates["model.CFM.d_model"] = d_model_val
    param_updates["model.CFM.num_layers"] = trial.suggest_int("cfm.num_layers", 3, 6)
    param_updates["model.CFM.dropout"] = trial.suggest_float("cfm.dropout", 0.1, 0.25)

    # ---- training è®­ç»ƒé…ç½® ----
    param_updates["training.learning_rate"] = trial.suggest_float(
        "training.learning_rate", 1e-4, 5e-3, log=True
    )
    param_updates["training.batch_size"] = trial.suggest_categorical("training.batch_size", [32, 64])

    # ---- anomaly_detection å¼‚å¸¸æ£€æµ‹é…ç½® ----
    param_updates["anomaly_detection.anomaly_ratio"] = trial.suggest_float(
        "anomaly_detection.anomaly_ratio", 1.5, 3.5
    )
    param_updates["anomaly_detection.threshold_strategy"] = trial.suggest_categorical(
        "anomaly_detection.threshold_strategy", ["percentile", "robust_percentile", "std", "adaptive"]
    )
    param_updates["anomaly_detection.aggregation_method"] = trial.suggest_categorical(
        "anomaly_detection.aggregation_method", ["mean", "max", "weighted_max"]
    )

    # 2. åˆ›å»ºå¹¶è¯„ä¼°å½“å‰è¯•éªŒçš„é…ç½®
    current_config = update_config(base_config, param_updates)

    try:
        predictions = swift_find_anomalies(data=data, config=current_config)
        score = affiliation_f(labels, predictions)
        return score
    except Exception as e:
        print(f"Trial {trial.number} failed with an exception: {e}")
        raise optuna.TrialPruned()


# --------------------------------------------------------------------------- #
#                               ä¸»ç¨‹åºæ‰§è¡Œé€»è¾‘                                #
# --------------------------------------------------------------------------- #

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ Optuna å¯¹ SWIFT è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–", formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("-c", "--config", type=str, required=True, help="åŸºç¡€é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "-d", "--dataset", type=str, required=True, help="ã€å®Œæ•´ã€‘æ•°æ®é›†æ–‡ä»¶è·¯å¾„ (ç”¨äºè®­ç»ƒ+éªŒè¯)"
    )
    parser.add_argument("-o", "--output", type=str, required=True, help="æœ€ä½³é…ç½®çš„è¾“å‡ºè·¯å¾„")
    parser.add_argument("--n-trials", type=int, default=100, help="è¦è¿è¡Œçš„æ€»è¯•éªŒæ¬¡æ•°")
    parser.add_argument(
        "--study-name", type=str, default="swift-tuning-study", help="Optuna ç ”ç©¶çš„åç§° (ç”¨äºç»­ä¼ )"
    )
    parser.add_argument(
        "--no-save-intermediate", action="store_true", help="å¦‚æœè®¾ç½®ï¼Œåˆ™ä¸åœ¨æ¯æ¬¡å‘ç°æ›´ä¼˜è§£æ—¶ä¿å­˜"
    )

    args = parser.parse_args()

    # éšæœºç§å­
    set_seed(1037)

    print("ğŸš€ å¼€å§‹ SWIFT å‚æ•°è‡ªåŠ¨è°ƒä¼˜...")
    base_config = load_config(args.config)
    df = pd.read_csv(args.dataset)
    data = df.iloc[:, :-1].values
    labels = df.iloc[:, -1].to_numpy()

    storage_name = f"sqlite:///{args.study_name}.db"
    study = optuna.create_study(
        study_name=args.study_name,
        storage=storage_name,
        direction="maximize",  # æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ– F1 åˆ†æ•°
        load_if_exists=True,  # å¦‚æœç ”ç©¶å·²å­˜åœ¨ï¼Œåˆ™åŠ è½½å®ƒï¼Œå®ç°æ–­ç‚¹ç»­ä¼ 
        sampler=optuna.samplers.TPESampler(),  # ä½¿ç”¨ TPE (ä¸€ç§è´å¶æ–¯ä¼˜åŒ–ç®—æ³•)
        pruner=optuna.pruners.MedianPruner(),  # ä½¿ç”¨ä¸­ä½æ•°å‰ªæå™¨ (å¯æå‰ç»ˆæ­¢æ— æœ›çš„è¯•éªŒ)
    )

    # 3. å®šä¹‰å›è°ƒå‡½æ•°ï¼Œç”¨äºå®æ—¶ä¿å­˜æœ€ä½³é…ç½®
    def save_best_callback(study: optuna.study.Study, trial: optuna.trial.FrozenTrial):
        """æ¯å½“å‘ç°æ›´å¥½çš„åˆ†æ•°æ—¶ï¼Œä¿å­˜ä¸€æ¬¡æœ€ä¼˜é…ç½®ã€‚"""
        # æ£€æŸ¥å½“å‰è¯•éªŒæ˜¯å¦æ˜¯è¿„ä»Šä¸ºæ­¢æœ€å¥½çš„
        if study.best_trial.number == trial.number:
            print(f"ğŸ‰ Trial {trial.number} å‘ç°æ–°çš„æœ€ä½³ Affiliation F1 åˆ†æ•°: {trial.value:.4f}")
            # å‚æ•°åé‡æ˜ å°„
            mapped_params = {
                k.replace("cfm.", "model.CFM.").replace("fm.", "model.FM."): v
                for k, v in trial.params.items()
            }
            save_optimal_config(base_config, mapped_params, args.output)

    # å°†é¢å¤–å‚æ•°é€šè¿‡ lambda ä¼ å…¥ objective å‡½æ•°
    objective_func = lambda trial: objective(trial, base_config, data, labels)

    callbacks = []
    if not args.no_save_intermediate:
        callbacks.append(save_best_callback)

    study.optimize(objective_func, n_trials=args.n_trials, callbacks=callbacks)

    print("\nğŸ‰ æœç´¢å®Œæˆ!")
