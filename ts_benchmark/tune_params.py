#!/usr/bin/env python3

"""
ä½¿ç”¨ Optuna å¯¹ SWIFT æ¨¡å‹è¿›è¡Œé«˜æ•ˆçš„è¶…å‚æ•°ä¼˜åŒ–ï¼ˆHPOï¼‰ã€‚

è¯¥è„šæœ¬æ›¿ä»£äº†åŸæœ‰çš„åŸºäºç½‘æ ¼æœç´¢çš„ tune_params.pyï¼Œå…·å¤‡ä»¥ä¸‹ä¼˜ç‚¹ï¼š
1.  **é«˜æ•ˆæœç´¢**: ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ç®—æ³• (TPE)ï¼Œè€Œéä½æ•ˆçš„ç½‘æ ¼æœç´¢ã€‚
2.  **æ–­ç‚¹ç»­ä¼ **: è‡ªåŠ¨å°†è¿›åº¦ä¿å­˜åˆ°SQLiteæ•°æ®åº“ï¼Œå¯éšæ—¶ä¸­æ–­å’Œæ¢å¤ã€‚
3.  **å®æ—¶ä¿å­˜**: æ¯å½“å‘ç°æ›´ä¼˜çš„é…ç½®æ—¶ï¼Œéƒ½ä¼šç«‹å³å°†å…¶ä¿å­˜åˆ° TOML æ–‡ä»¶ã€‚
4.  **æ¸…æ™°çš„ä¾èµ–å¤„ç†**: ä¼˜é›…åœ°å¤„ç†äº† d_model >= d_cf è¿™ç±»å‚æ•°ä¾èµ–ã€‚
5.  **æ”¯æŒå¹¶è¡Œ**: ï¼ˆéœ€ç¨ä½œé…ç½®ï¼‰Optuna æ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œè°ƒä¼˜ã€‚

ä½¿ç”¨æ–¹æ³•:
    python tune_with_optuna.py \
        -c configs/find_anomalies/ASD1/swift.toml \
        -d ./datasets/processed/ASD/train_1.csv \
        -o configs/find_anomalies/ASD1/swift_optuna_best.toml \
        --n-trials 100 \
        --study-name "swift-asd-tuning"
"""

import argparse
import copy
import os
from typing import Any, Dict

import numpy as np
import optuna
import pandas as pd
import tomli
import tomli_w
from baselines.swift.swift_pipeline import swift_find_anomalies
from evaluation.metrics.anomaly_detection_metrics_label import affiliation_f
from tools.tools import set_seed

# --------------------------------------------------------------------------- #
#                             è¾…åŠ©å‡½æ•° (æ¥è‡ªåŸè„šæœ¬)                             #
# --------------------------------------------------------------------------- #


def load_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½ TOML é…ç½®æ–‡ä»¶ã€‚"""
    with open(config_path, "rb") as f:
        return tomli.load(f)


def update_config(base_config: Dict[str, Any], param_updates: Dict[str, Any]) -> Dict[str, Any]:
    """æ ¹æ® Optuna æä¾›çš„å‚æ•°æ›´æ–°é…ç½®å­—å…¸ã€‚"""
    config = copy.deepcopy(base_config)
    for key_path, value in param_updates.items():
        keys = key_path.split(".")
        current = config
        for key in keys[:-1]:
            current = current.get(key, {})
        current[keys[-1]] = value
    return config


def save_optimal_config(base_config: Dict[str, Any], best_params: Dict[str, Any], output_path: str):
    """å°†ä¼˜åŒ–åçš„é…ç½®ä¿å­˜åˆ° TOML æ–‡ä»¶ã€‚"""
    if not best_params:
        print("ğŸŸ¡ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆå‚æ•°ï¼Œä¸ä¿å­˜é…ç½®æ–‡ä»¶ã€‚")
        return

    optimal_config = update_config(base_config, best_params)
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, "wb") as f:
        tomli_w.dump(optimal_config, f)
    print(f"ğŸ’¾ æ–°çš„æœ€ä½³é…ç½®å·²ä¿å­˜åˆ°: {output_path}")


# --------------------------------------------------------------------------- #
#                       Optuna æ ¸å¿ƒç›®æ ‡å‡½æ•° (Objective)                         #
# --------------------------------------------------------------------------- #


def objective(
    trial: optuna.trial.Trial, base_config: Dict[str, Any], data: np.ndarray, labels: np.ndarray
) -> float:
    """
    Optuna çš„ç›®æ ‡å‡½æ•° (ç¬¬ä¸€é˜¶æ®µï¼šæ ¸å¿ƒæ¶æ„ä¸æŸå¤±å‡½æ•°è°ƒä¼˜)ã€‚
    ç”¨äºè¯„ä¼°ä¸€ç»„å¯¹æ¨¡å‹æ€§èƒ½å½±å“æœ€å¤§çš„è¶…å‚æ•°é…ç½®ã€‚
    """
    param_updates = {}
    param_updates["trial_number"] = trial.number

    # 1. å®šä¹‰è¶…å‚æ•°çš„æœç´¢ç©ºé—´ (ç¬¬ä¸€é˜¶æ®µ)
    # -----------------------------------------------------------------------
    # [loss] - æŸå¤±å‡½æ•°æƒé‡ï¼Œæä¸ºé‡è¦
    # -----------------------------------------------------------------------
    param_updates["loss.ccd_loss_lambda"] = trial.suggest_float("loss.ccd_loss_lambda", 1e-4, 1e-1, log=True)
    param_updates["loss.scale_loss_lambda"] = trial.suggest_float("loss.scale_loss_lambda", 0.2, 1.0)
    param_updates["loss.ccd_regular_lambda"] = trial.suggest_float("loss.ccd_regular_lambda", 0.05, 0.5)
    param_updates["loss.ccd_align_lambda"] = trial.suggest_float("loss.ccd_align_lambda", 0.5, 2.0)

    # -----------------------------------------------------------------------
    # [model.FM] - å°æ³¢åˆ†è§£å±‚æ•°
    # -----------------------------------------------------------------------
    # æ³¨æ„: levelçš„æ”¹å˜ä¼šå½±å“æ‰©å±•åçš„é€šé“æ•°ï¼Œè¿›è€Œå½±å“GATæ¨¡å—ï¼Œè¿™æ˜¯æ ¸å¿ƒçš„ç»“æ„å‚æ•°
    param_updates["model.FM.level"] = trial.suggest_int("fm.level", 2, 5)

    # -----------------------------------------------------------------------
    # [model.CFM] - Transformer æ ¸å¿ƒå‚æ•°
    # -----------------------------------------------------------------------
    param_updates["model.CFM.num_heads"] = trial.suggest_categorical("cfm.num_heads", [2, 4, 8])
    param_updates["model.CFM.attention_dropout"] = trial.suggest_float("cfm.attention_dropout", 0.05, 0.3)

    # ä¿ç•™åŸæœ‰çš„å…³é”®å‚æ•°
    d_cf_val = trial.suggest_categorical("cfm.d_cf", [64, 96, 128])
    param_updates["model.CFM.d_cf"] = d_cf_val
    valid_d_model_choices = [val for val in [64, 96, 128] if val >= d_cf_val]
    if not valid_d_model_choices:
        raise optuna.TrialPruned()
    param_updates["model.CFM.d_model"] = trial.suggest_categorical("cfm.d_model", valid_d_model_choices)
    param_updates["model.CFM.num_layers"] = trial.suggest_int("cfm.num_layers", 3, 6)
    param_updates["model.CFM.dropout"] = trial.suggest_float("cfm.dropout", 0.1, 0.25)

    # -----------------------------------------------------------------------
    # [training] - ä¿ç•™çš„å…³é”®è®­ç»ƒå‚æ•°
    # -----------------------------------------------------------------------
    param_updates["training.learning_rate"] = trial.suggest_float("train.learning_rate", 1e-4, 5e-3, log=True)
    param_updates["training.batch_size"] = trial.suggest_categorical("train.batch_size", [32, 64])

    # -----------------------------------------------------------------------
    # [anomaly_detection] - ä¿ç•™çš„å…³é”®æ£€æµ‹é€»è¾‘å‚æ•°
    # -----------------------------------------------------------------------
    param_updates["anomaly_detection.anomaly_ratio"] = trial.suggest_float("ad.anomaly_ratio", 1.5, 3.5)
    param_updates["anomaly_detection.aggregation_method"] = trial.suggest_categorical(
        "ad.aggregation_method", ["mean", "max", "weighted_max"]
    )

    # 2. åˆ›å»ºå¹¶è¯„ä¼°å½“å‰è¯•éªŒçš„é…ç½®
    current_config = update_config(base_config, param_updates)

    try:
        # swift_find_anomalies å°è£…äº†è®­ç»ƒå’Œé¢„æµ‹
        predictions = swift_find_anomalies(data=data, config=current_config)
        score = affiliation_f(labels, predictions)
        return score
    except Exception as e:
        # å¦‚æœå‘ç”Ÿä»»ä½•é”™è¯¯ (å¦‚ CUDA OOM), æ‰“å°é”™è¯¯å¹¶å‘Šè¯‰ Optuna è¯¥è¯•éªŒå¤±è´¥äº†
        print(f"Trial {trial.number} failed with an exception: {e}")
        # è¿”å›ä¸€ä¸ªå¾ˆå·®çš„åˆ†æ•°æˆ–ç›´æ¥å‰ªæ
        raise optuna.TrialPruned()


# --------------------------------------------------------------------------- #
#                               ä¸»ç¨‹åºæ‰§è¡Œé€»è¾‘                                #
# --------------------------------------------------------------------------- #

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ Optuna å¯¹ SWIFT è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–", formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("-c", "--config", type=str, required=True, help="åŸºç¡€é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "-d", "--dataset", type=str, required=True, help="ã€å®Œæ•´ã€‘æ•°æ®é›†æ–‡ä»¶è·¯å¾„ (ç”¨äºè®­ç»ƒ+éªŒè¯)"
    )
    parser.add_argument("-o", "--output", type=str, required=True, help="æœ€ä½³é…ç½®çš„è¾“å‡ºè·¯å¾„")
    parser.add_argument("--n-trials", type=int, default=100, help="è¦è¿è¡Œçš„æ€»è¯•éªŒæ¬¡æ•°")
    parser.add_argument(
        "--study-name", type=str, default="swift-tuning-study", help="Optuna ç ”ç©¶çš„åç§° (ç”¨äºç»­ä¼ )"
    )
    parser.add_argument(
        "--no-save-intermediate", action="store_true", help="å¦‚æœè®¾ç½®ï¼Œåˆ™ä¸åœ¨æ¯æ¬¡å‘ç°æ›´ä¼˜è§£æ—¶ä¿å­˜"
    )

    args = parser.parse_args()

    # åœ¨å¼€å§‹æ—¶è®¾ç½®ä¸€æ¬¡éšæœºç§å­
    set_seed(1037)

    # 1. åŠ è½½æ•°æ®å’ŒåŸºç¡€é…ç½®
    print("ğŸš€ å¼€å§‹ SWIFT å‚æ•°è‡ªåŠ¨è°ƒä¼˜ (ä½¿ç”¨ Optuna)...")
    base_config = load_config(args.config)
    df = pd.read_csv(args.dataset)
    data = df.iloc[:, :-1].values
    labels = df.iloc[:, -1].to_numpy()
    print(f"âœ… æ•°æ®é›† {args.dataset} åŠ è½½å®Œæˆ, å½¢çŠ¶: {data.shape}")
    print(f"âœ… åŸºç¡€é…ç½® {args.config} åŠ è½½å®Œæˆ")

    # 2. è®¾ç½®å¹¶åˆ›å»º Optuna Study
    # ä½¿ç”¨ SQLite æ•°æ®åº“æ¥å­˜å‚¨ç ”ç©¶ç»“æœï¼Œè¿™æ ·å¯ä»¥éšæ—¶ä¸­æ–­å’Œæ¢å¤
    storage_name = f"sqlite:///{args.study_name}.db"
    study = optuna.create_study(
        study_name=args.study_name,
        storage=storage_name,
        direction="maximize",  # æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ– F1 åˆ†æ•°
        load_if_exists=True,  # å¦‚æœç ”ç©¶å·²å­˜åœ¨ï¼Œåˆ™åŠ è½½å®ƒï¼Œå®ç°æ–­ç‚¹ç»­ä¼ 
        sampler=optuna.samplers.TPESampler(),  # ä½¿ç”¨ TPE (ä¸€ç§è´å¶æ–¯ä¼˜åŒ–ç®—æ³•)
        pruner=optuna.pruners.MedianPruner(),  # ä½¿ç”¨ä¸­ä½æ•°å‰ªæå™¨ (å¯æå‰ç»ˆæ­¢æ— æœ›çš„è¯•éªŒ)
    )
    print(f"ğŸ“ˆ Optuna Study '{args.study_name}' å·²è®¾ç½®ã€‚")
    print(f"   - æ•°æ®åº“: {storage_name}")
    print(f"   - å·²å®Œæˆè¯•éªŒæ•°: {len(study.trials)}")
    print(f"   - æœ¬æ¬¡å°†è¿è¡Œè¯•éªŒæ•°: {args.n_trials}")

    # 3. å®šä¹‰å›è°ƒå‡½æ•°ï¼Œç”¨äºå®æ—¶ä¿å­˜æœ€ä½³é…ç½®
    def save_best_callback(study: optuna.study.Study, trial: optuna.trial.FrozenTrial):
        """æ¯å½“å‘ç°æ›´å¥½çš„åˆ†æ•°æ—¶ï¼Œä¿å­˜ä¸€æ¬¡æœ€ä¼˜é…ç½®ã€‚"""
        # æ£€æŸ¥å½“å‰è¯•éªŒæ˜¯å¦æ˜¯è¿„ä»Šä¸ºæ­¢æœ€å¥½çš„
        if study.best_trial.number == trial.number:
            print(f"ğŸ‰ Trial {trial.number} å‘ç°æ–°çš„æœ€ä½³åˆ†æ•°: {trial.value:.4f}")
            save_optimal_config(base_config, trial.params, args.output)

    # 4. å¼€å§‹ä¼˜åŒ–
    print("\nğŸ”¥ å¼€å§‹ä¼˜åŒ–... æŒ‰ Ctrl+C å¯éšæ—¶å®‰å…¨é€€å‡ºå¹¶ç»­ä¼ ã€‚")

    # å°†é¢å¤–å‚æ•°é€šè¿‡ lambda ä¼ å…¥ objective å‡½æ•°
    objective_func = lambda trial: objective(trial, base_config, data, labels)

    callbacks = []
    if not args.no_save_intermediate:
        callbacks.append(save_best_callback)

    study.optimize(objective_func, n_trials=args.n_trials, callbacks=callbacks)

    # 5. æ‰“å°æœ€ç»ˆç»“æœ
    print("\nğŸ‰ æœç´¢å®Œæˆ!")
    print(f"   - æ€»è¯•éªŒæ¬¡æ•°: {len(study.trials)}")

    # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°äº†ä»»ä½•æœ‰æ•ˆçš„è¯•éªŒ
    if study.best_trial:
        print(f"ğŸ† æœ€ä½³ F1 åˆ†æ•°: {study.best_value:.4f}")
        print("ğŸ“‹ æœ€ä½³å‚æ•°ç»„åˆ:")
        for key, value in study.best_params.items():
            print(f"   - {key}: {value}")

        # ç¡®ä¿æœ€ç»ˆçš„æœ€ä½³é…ç½®è¢«ä¿å­˜
        final_best_params_renamed = {
            k.replace("ad.", "anomaly_detection.")
            .replace("cfm.", "model.CFM.")
            .replace("train.", "training."): v
            for k, v in study.best_params.items()
        }
        save_optimal_config(base_config, final_best_params_renamed, args.output)
    else:
        print("âŒ æœªèƒ½å®Œæˆä»»ä½•æœ‰æ•ˆçš„è¯•éªŒï¼Œæ— æ³•ç¡®å®šæœ€ä½³å‚æ•°ã€‚")
