import argparse
import copy
import gc
import os
from typing import Any, Dict, List, Union

import numpy as np
import optuna
import pandas as pd
import tomli
import tomli_w
import torch
from baselines.swift.swift_pipeline import swift_find_anomalies, swift_score_anomalies
from evaluation.metrics.anomaly_detection_metrics_label import affiliation_f
from evaluation.metrics.anomaly_detection_metrics_score import auc_roc
from tools.tools import set_seed


def clear_gpu_memory():
    """æ¸…ç†GPUå†…å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()


# ========== ç»Ÿä¸€å‚æ•°é…ç½® ==========
PARAM_CONFIG = {
    "seq_len": {
        "type": "categorical",
        "choices": [64, 128],
        "config_path": "data.seq_len",
    },
    "patch_size": {
        "type": "categorical",
        "choices": [8, 16, 32],
        "config_path": "data.patch_size",
    },
    "patch_stride": {
        "type": "categorical",
        "choices": [4, 8, 16],
        "config_path": "data.patch_stride",
    },
    "d_cf": {
        "type": "categorical",
        "choices": [32, 64, 96],
        "config_path": "model.CFM.d_cf",
    },
    "d_model": {
        "type": "categorical",
        "choices": [64, 96, 128],
        "config_path": "model.CFM.d_model",
    },
    "cfm_num_heads": {
        "type": "categorical",
        "choices": [2, 4],
        "config_path": "model.CFM.num_heads",
    },
    "cfm_attention_dropout": {
        "type": "float",
        "low": 0.1,
        "high": 0.2,
        "config_path": "model.CFM.attention_dropout",
        "decimal_places": 3,
    },
    "cfm_num_layers": {
        "type": "int",
        "low": 3,
        "high": 5,
        "config_path": "model.CFM.num_layers",
    },
    "cfm_dropout": {
        "type": "float",
        "low": 0.1,
        "high": 0.2,
        "config_path": "model.CFM.dropout",
        "decimal_places": 3,
    },
    "cfm_num_gat_heads": {
        "type": "categorical",
        "choices": [2, 4],
        "config_path": "model.CFM.num_gat_heads",
    },
    "cfm_gat_head_dim": {
        "type": "categorical",
        "choices": [8, 16],
        "config_path": "model.CFM.gat_head_dim",
    },
    "fm_level": {
        "type": "int",
        "low": 2,
        "high": 4,
        "config_path": "model.FM.level",
    },
    "fm_wavelet": {
        "type": "categorical",
        "choices": ["db4", "sym4", "coif2"],
        "config_path": "model.FM.wavelet",
    },
    # æ—¶åºé‡æ„å‚æ•°
    "tsrm_is_flatten_individual": {
        "type": "categorical",
        "choices": [True, False],
        "config_path": "model.TSRM.is_flatten_individual",
    },
    # æŸå¤±å‡½æ•°å‚æ•°
    "ccd_loss_lambda": {
        "type": "float",
        "low": 1e-4,
        "high": 1e-1,
        "log": True,
        "config_path": "loss.ccd_loss_lambda",
        "decimal_places": 5,
    },
    "scale_loss_lambda": {
        "type": "float",
        "low": 0.2,
        "high": 1.0,
        "config_path": "loss.scale_loss_lambda",
        "decimal_places": 3,
    },
    "ccd_regular_lambda": {
        "type": "float",
        "low": 0.05,
        "high": 0.5,
        "config_path": "loss.ccd_regular_lambda",
        "decimal_places": 3,
    },
    "ccd_align_lambda": {
        "type": "float",
        "low": 0.5,
        "high": 2.0,
        "config_path": "loss.ccd_align_lambda",
        "decimal_places": 3,
    },
    # è®­ç»ƒå‚æ•°
    "learning_rate": {
        "type": "float",
        "low": 1e-4,
        "high": 5e-3,
        "log": True,
        "config_path": "training.learning_rate",
        "decimal_places": 5,
    },
    # å¼‚å¸¸æ£€æµ‹å‚æ•°
    "scale_score_lambda": {
        "type": "float",
        "low": 0.1,
        "high": 1.0,
        "config_path": "anomaly_detection.scale_score_lambda",
        "decimal_places": 3,
    },
}


def load_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½ toml é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, "rb") as f:
            return tomli.load(f)
    except FileNotFoundError:
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    except Exception as e:
        raise ValueError(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")


def update_config(base_config: Dict[str, Any], param_updates: Dict[str, Any]) -> Dict[str, Any]:
    """æ›´æ–° toml é…ç½®æ–‡ä»¶"""
    config = copy.deepcopy(base_config)
    for key_path, value in param_updates.items():
        # æ”¯æŒä½¿ç”¨è¯¸å¦‚ "model.CFM.d_cf" è¿™æ ·çš„ç‚¹è¯­æ³•æ›´æ–°åµŒå¥—å­—æ®µ
        keys = key_path.split(".")
        current = config
        # ä¾æ¬¡å‘ä¸‹æŸ¥æ‰¾/åˆ›å»ºåµŒå¥—å­—å…¸
        for key in keys[:-1]:
            if key not in current or not isinstance(current[key], dict):
                current[key] = {}
            current = current[key]

        # æ›´æ–°æœ€ç»ˆé”®å¯¹åº”çš„å€¼
        current[keys[-1]] = value
    return config


def save_config(config: Dict[str, Any], output_path: str):
    """ä¿å­˜ toml é…ç½®æ–‡ä»¶"""
    try:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, "wb") as f:
            tomli_w.dump(config, f)
        print(f"ğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")


def suggest_parameter(
    trial: optuna.trial.Trial, param_name: str, param_config: Dict[str, Any]
) -> Any:
    """æ ¹æ®å‚æ•°é…ç½®åŠ¨æ€å»ºè®®å‚æ•°å€¼"""
    param_type = param_config["type"]

    if param_type == "categorical":
        return trial.suggest_categorical(param_name, param_config["choices"])
    elif param_type == "int":
        return trial.suggest_int(param_name, param_config["low"], param_config["high"])
    elif param_type == "float":
        log = param_config.get("log", False)
        value = trial.suggest_float(param_name, param_config["low"], param_config["high"], log=log)
        # å¦‚æœé…ç½®äº†å°æ•°ä½æ•°ï¼Œåˆ™è¿›è¡Œå››èˆäº”å…¥
        decimal_places = param_config.get("decimal_places")
        if decimal_places is not None:
            value = round(value, decimal_places)
        return value
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å‚æ•°ç±»å‹: {param_type}")


def validate_params(params: Dict[str, Any]) -> bool:
    """éªŒè¯å‚æ•°ç»„åˆçš„æœ‰æ•ˆæ€§"""
    seq_len = params["seq_len"]
    patch_size = params["patch_size"]
    patch_stride = params["patch_stride"]
    d_model = params["d_model"]
    d_cf = params["d_cf"]

    # åŸºæœ¬çº¦æŸæ£€æŸ¥
    if patch_size >= seq_len:
        return False
    if (seq_len - patch_size) % patch_stride != 0:
        return False
    if patch_stride > patch_size:
        return False
    if d_model < d_cf:
        return False

    return True


def objective(
    trial: optuna.trial.Trial,
    base_config: Dict[str, Any],
    all_data: np.ndarray,
    labels: np.ndarray,
    task_name: str,
) -> float:
    """Optunaç›®æ ‡å‡½æ•°"""

    # åœ¨æ¯æ¬¡è¯•éªŒå¼€å§‹å‰æ¸…ç†GPUå†…å­˜
    clear_gpu_memory()

    # åŠ¨æ€ç”Ÿæˆæ‰€æœ‰å‚æ•°
    params = {}
    for param_name, param_config in PARAM_CONFIG.items():
        params[param_name] = suggest_parameter(trial, param_name, param_config)

    # éªŒè¯å‚æ•°ç»„åˆ
    if not validate_params(params):
        raise optuna.TrialPruned("æ— æ•ˆçš„å‚æ•°ç»„åˆ")

    # æ„å»ºå‚æ•°æ›´æ–°å­—å…¸
    param_updates = {}
    for param_name, value in params.items():
        config_path = PARAM_CONFIG[param_name]["config_path"]
        param_updates[config_path] = value

    # æ›´æ–°é…ç½®
    current_config = update_config(base_config, param_updates)
    # è®¾ç½® trial_number ç”¨äºæ—¥å¿—è®°å½•
    current_config["trial_number"] = trial.number

    try:
        if task_name == "find_anomalies":
            # å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ - ä½¿ç”¨ F1 åˆ†æ•°
            predictions = swift_find_anomalies(all_data=all_data, config=current_config)
            result = affiliation_f(labels, predictions)
        elif task_name == "score_anomalies":
            # å¼‚å¸¸è¯„åˆ†ä»»åŠ¡ - ä½¿ç”¨ AUC-ROC
            scores = swift_score_anomalies(all_data=all_data, config=current_config)
            result = auc_roc(labels, scores)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_name}")

        clear_gpu_memory()  # æ¸…ç†å†…å­˜
        return float(result)

    except torch.cuda.OutOfMemoryError as e:
        print(f"ğŸ’¥ Trial {trial.number} GPUå†…å­˜ä¸è¶³: {str(e)[:100]}...")
        clear_gpu_memory()
        raise optuna.TrialPruned(f"GPUå†…å­˜ä¸è¶³: {e}")

    except Exception as e:
        print(f"âŒ Trial {trial.number} æ‰§è¡Œå¤±è´¥: {e}")
        clear_gpu_memory()
        raise optuna.TrialPruned(f"è¯•éªŒæ‰§è¡Œå¤±è´¥: {e}")


def run_optimization(args: argparse.Namespace):
    """è¿è¡Œ Optuna è¶…å‚æ•°ä¼˜åŒ–æµç¨‹"""
    print("ğŸš€ å¼€å§‹è¶…å‚æ•°è°ƒä¼˜...")
    print(f"ğŸ¯ ä»»åŠ¡: {args.task_name} | æ•°æ®é›†: {args.dataset_name} | ç®—æ³•: {args.algorithm_name}")
    print(f"ğŸ”¬ å¼‚å¸¸ç‡: {args.anomaly_ratio}% | è¯•éªŒæ¬¡æ•°: {args.n_trials}")

    # éªŒè¯ä»»åŠ¡ç±»å‹
    if args.task_name not in ["find_anomalies", "score_anomalies"]:
        print(f"âŒ ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {args.task_name}")
        print("ğŸ“ æ”¯æŒçš„ä»»åŠ¡ç±»å‹: find_anomalies, score_anomalies")
        return

    # æ ¹æ®ä»»åŠ¡ç±»å‹ç¡®å®šè¯„ä¼°æŒ‡æ ‡åç§°
    metric_name = "Aff-F" if args.task_name == "find_anomalies" else "A-R"

    # ---------- åŠ è½½åŸºç¡€é…ç½®ä¸æ•°æ® ----------
    try:
        base_config = load_config(args.base_config)
        # å¼‚å¸¸ç‡è®¾ç½®
        base_config["anomaly_detection"]["anomaly_ratio"] = args.anomaly_ratio
        # è®­ç»ƒéªŒè¯é›†é•¿åº¦è®¾ç½®
        base_config["data"]["tain_val_len"] = args.train_val_len

        df = pd.read_csv(args.dataset_path)
        all_data = df.iloc[:, :-1].values  # è®­ç»ƒéªŒè¯æµ‹è¯•é›†
        test_labels = df.iloc[args.train_val_len :, -1].to_numpy()  # æµ‹è¯•é›†æ ‡ç­¾

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    # ---------- åˆ›å»º Optuna Study ----------
    study = optuna.create_study(
        direction="maximize",
        sampler=optuna.samplers.TPESampler(),
        pruner=optuna.pruners.MedianPruner(),
    )

    # ---------- å›è°ƒç”¨äºè¿½è¸ªæœ€ä½³ç»“æœ ----------
    best_value: float = -1.0
    best_params: Dict[str, Any] = {}
    best_config_path: str = ""  # è®°å½•å½“å‰æœ€ä½³é…ç½®æ–‡ä»¶è·¯å¾„

    def _callback(study: optuna.Study, trial: optuna.trial.FrozenTrial):
        nonlocal best_value, best_params, best_config_path
        if (
            trial.state == optuna.trial.TrialState.COMPLETE
            and trial.value is not None
            and trial.value > best_value
        ):
            # åˆ é™¤ä¹‹å‰çš„æœ€ä½³é…ç½®æ–‡ä»¶
            if best_config_path and os.path.exists(best_config_path):
                try:
                    os.remove(best_config_path)
                    print(f"ğŸ—‘ï¸ åˆ é™¤ä¹‹å‰çš„é…ç½®: {os.path.basename(best_config_path)}")
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")

            best_value = trial.value
            best_params = trial.params.copy()
            print(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³ç»“æœ: {metric_name} = {best_value:.3f} (Trial {trial.number})")

            param_updates = {}
            for param_name, value in trial.params.items():
                if param_name in PARAM_CONFIG:
                    config_path = PARAM_CONFIG[param_name]["config_path"]
                    param_updates[config_path] = value

            current_best_config = update_config(base_config, param_updates)

            # ç”ŸæˆåŒ…å«æŒ‡æ ‡åˆ†æ•°çš„æ–‡ä»¶å
            base_output_config = args.output_config.replace(".toml", "")
            metric_suffix = "aff-f" if args.task_name == "find_anomalies" else "a-r"
            output_config_with_score = f"{base_output_config}_{metric_suffix}_{best_value:.3f}.toml"
            best_config_path = output_config_with_score  # æ›´æ–°æœ€ä½³é…ç½®è·¯å¾„

            save_config(current_best_config, output_config_with_score)

    # ---------- æ‰§è¡Œä¼˜åŒ– ----------
    try:
        study.optimize(
            lambda t: objective(t, base_config, all_data, test_labels, args.task_name),
            n_trials=args.n_trials,
            callbacks=[_callback],
        )
    except KeyboardInterrupt:
        print("â¹ï¸ ä¼˜åŒ–è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–è¿‡ç¨‹å‡ºé”™: {e}")

    # ---------- æœ€ç»ˆç»“æœæ€»ç»“ ----------
    if best_params:
        print("\nâœ… è°ƒä¼˜å®Œæˆ!")
        print(f"ğŸ“Š æœ€ä½³ {metric_name} åˆ†æ•°: {best_value:.3f}")
    else:
        print("\nâš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æœ€ä½³å‚æ•°ï¼Œè¯·æ£€æŸ¥æ•°æ®å’Œé…ç½®")


# --------------------------- CLI ---------------------------
if __name__ == "__main__":
    cli_parser = argparse.ArgumentParser(description="SWIFT è¶…å‚æ•°è°ƒä¼˜å·¥å…·")

    # åŸºæœ¬å‚æ•°
    cli_parser.add_argument("--task-name", type=str, required=True, help="ä»»åŠ¡åç§°")
    cli_parser.add_argument("--dataset-name", type=str, required=True, help="æ•°æ®é›†åç§°")
    cli_parser.add_argument("--train-val-len", type=int, required=True, help="è®­ç»ƒéªŒè¯é›†æ€»é•¿åº¦")
    cli_parser.add_argument("--algorithm-name", type=str, required=True, help="ç®—æ³•åç§°")
    cli_parser.add_argument("--anomaly-ratio", type=float, required=True, help="å¼‚å¸¸ç‡ (ç™¾åˆ†æ¯”)")
    cli_parser.add_argument("--n-trials", type=int, required=True, help="Optuna è¯•éªŒæ¬¡æ•°")

    # è·¯å¾„å‚æ•°
    cli_parser.add_argument(
        "--base-config",
        type=str,
        default="configs/base/{algorithm_name}.toml",
        help="åŸºç¡€é…ç½®æ–‡ä»¶è·¯å¾„",
    )
    cli_parser.add_argument(
        "--output-config",
        type=str,
        default="configs/{task_name}/{dataset_name}/{algorithm_name}.toml",
        help="è¾“å‡ºé…ç½®æ–‡ä»¶è·¯å¾„",
    )
    cli_parser.add_argument(
        "--dataset-path",
        type=str,
        default="datasets/{dataset_name}.csv",
        help="æ•°æ®é›†æ–‡ä»¶è·¯å¾„",
    )

    _args = cli_parser.parse_args()

    set_seed(1037)  # éšæœºç§å­

    _args.base_config = _args.base_config.format(
        task_name=_args.task_name,
        dataset_name=_args.dataset_name,
        algorithm_name=_args.algorithm_name,
    )
    # å…ˆæ ¼å¼åŒ–åŸºæœ¬ä¿¡æ¯
    _args.output_config = _args.output_config.format(
        task_name=_args.task_name,
        dataset_name=_args.dataset_name,
        algorithm_name=_args.algorithm_name,
    )

    # æ ¹æ®ä»»åŠ¡ç±»å‹å†³å®šæ˜¯å¦æ·»åŠ  ratio å­—æ®µ
    if _args.task_name == "find_anomalies":
        # ä¸º find_anomalies ä»»åŠ¡æ·»åŠ  ratio å­—æ®µ
        base_name = _args.output_config.replace(".toml", "")
        _args.output_config = f"{base_name}_ratio_{_args.anomaly_ratio}.toml"
    _args.dataset_path = _args.dataset_path.format(dataset_name=_args.dataset_name)

    run_optimization(_args)
