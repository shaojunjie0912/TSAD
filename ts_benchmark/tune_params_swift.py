import argparse
import copy
import gc
import os
from typing import Any, Dict, List, Union

import numpy as np
import optuna
import optuna.visualization as vis
import pandas as pd
import plotly.graph_objects as go
import tomli
import tomli_w
import torch
from baselines.swift.swift_pipeline import swift_find_anomalies, swift_score_anomalies
from evaluation.metrics.anomaly_detection_metrics_label import affiliation_f
from evaluation.metrics.anomaly_detection_metrics_score import auc_roc
from tools.tools import set_seed

# TODO: é‡åˆ° cuda out of memory, é‚£ä¹ˆæ­¤æ—¶çš„å‚æ•°ç»„åˆæ˜¯å¦éœ€è¦é‡è¯•?


def clear_gpu_memory():
    """æ¸…ç†GPUå†…å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()


def create_study_name(args: argparse.Namespace) -> str:
    """åˆ›å»ºstudyåç§°"""
    return f"{args.task_name}_{args.dataset_name}_{args.algorithm_name}_ratio_{args.anomaly_ratio}"


def create_study_db_path(args: argparse.Namespace) -> str:
    """åˆ›å»ºstudyæ•°æ®åº“è·¯å¾„"""
    study_name = create_study_name(args)
    db_dir = "optuna_studies"
    os.makedirs(db_dir, exist_ok=True)
    return os.path.join(db_dir, f"{study_name}.db")


def generate_optimization_plots(study: optuna.Study, args: argparse.Namespace) -> None:
    """ç”Ÿæˆä¼˜åŒ–è¿‡ç¨‹çš„å¯è§†åŒ–å›¾è¡¨"""
    if len(study.trials) == 0:
        print("âš ï¸ æ²¡æœ‰è¯•éªŒæ•°æ®ï¼Œè·³è¿‡å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆ")
        return

    # åˆ›å»ºå¯è§†åŒ–è¾“å‡ºç›®å½•
    viz_dir = f"optuna_visualizations/{args.dataset_name}/{args.algorithm_name}"
    os.makedirs(viz_dir, exist_ok=True)

    # æ ¹æ®ä»»åŠ¡ç±»å‹ç¡®å®šæŒ‡æ ‡åç§°
    metric_name = "Affiliation-F" if args.task_name == "find_anomalies" else "AUC-ROC"

    try:
        # 1. ä¼˜åŒ–å†å²å›¾ - æ˜¾ç¤ºæ¯æ¬¡è¯•éªŒçš„ç»“æœå’Œæœ€ä½³å€¼è¶‹åŠ¿
        print("ğŸ“Š ç”Ÿæˆä¼˜åŒ–å†å²å›¾...")
        fig_history = vis.plot_optimization_history(study)
        fig_history.update_layout(
            title=f"ä¼˜åŒ–å†å² - {args.dataset_name} ({metric_name})",
            xaxis_title="è¯•éªŒæ¬¡æ•°",
            yaxis_title=f"{metric_name} åˆ†æ•°",
        )
        fig_history.write_html(f"{viz_dir}/optimization_history.html")

        # 2. å‚æ•°é‡è¦æ€§å›¾ - æ˜¾ç¤ºå“ªäº›å‚æ•°å¯¹ç»“æœå½±å“æœ€å¤§
        print("ğŸ“Š ç”Ÿæˆå‚æ•°é‡è¦æ€§å›¾...")
        fig_importance = vis.plot_param_importances(study)
        fig_importance.update_layout(
            title=f"å‚æ•°é‡è¦æ€§ - {args.dataset_name}", xaxis_title="é‡è¦æ€§"
        )
        fig_importance.write_html(f"{viz_dir}/param_importances.html")

        # 3. å‚æ•°å…³ç³»å›¾ - æ˜¾ç¤ºå‚æ•°ä¹‹é—´çš„ç›¸å…³æ€§
        print("ğŸ“Š ç”Ÿæˆå‚æ•°å…³ç³»å›¾...")
        fig_slice = vis.plot_slice(study)
        fig_slice.update_layout(title=f"å‚æ•°åˆ‡ç‰‡åˆ†æ - {args.dataset_name}")
        fig_slice.write_html(f"{viz_dir}/param_slice.html")

        # 4. å¹¶è¡Œåæ ‡å›¾ - æ˜¾ç¤ºé«˜æ€§èƒ½è¯•éªŒçš„å‚æ•°ç»„åˆ
        print("ğŸ“Š ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾...")
        fig_parallel = vis.plot_parallel_coordinate(study)
        fig_parallel.update_layout(title=f"å¹¶è¡Œåæ ‡å›¾ - {args.dataset_name}")
        fig_parallel.write_html(f"{viz_dir}/parallel_coordinate.html")

        # 5. æ”¶æ•›åˆ†æ - è‡ªå®šä¹‰å›¾è¡¨åˆ†ææ”¶æ•›æƒ…å†µ
        print("ğŸ“Š ç”Ÿæˆæ”¶æ•›åˆ†æå›¾...")
        completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]
        if len(completed_trials) > 1:
            trial_numbers = [t.number for t in completed_trials]
            trial_values = [t.value for t in completed_trials]

            # è®¡ç®—è¿è¡Œæœ€ä½³å€¼
            best_values = []
            current_best = float("-inf")
            for value in trial_values:
                if value is not None and value > current_best:
                    current_best = value
                best_values.append(current_best)

            # åˆ›å»ºæ”¶æ•›å›¾
            fig_convergence = go.Figure()
            fig_convergence.add_trace(
                go.Scatter(
                    x=trial_numbers,
                    y=trial_values,
                    mode="markers",
                    name="è¯•éªŒç»“æœ",
                    marker=dict(color="lightblue", size=8),
                )
            )
            fig_convergence.add_trace(
                go.Scatter(
                    x=trial_numbers,
                    y=best_values,
                    mode="lines+markers",
                    name="æœ€ä½³å€¼è¶‹åŠ¿",
                    line=dict(color="red", width=2),
                )
            )
            fig_convergence.update_layout(
                title=f"æ”¶æ•›åˆ†æ - {args.dataset_name}",
                xaxis_title="è¯•éªŒæ¬¡æ•°",
                yaxis_title=f"{metric_name} åˆ†æ•°",
                hovermode="x unified",
            )
            fig_convergence.write_html(f"{viz_dir}/convergence_analysis.html")

        print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {viz_dir}")
        print(f"ğŸ“Š å¯åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ HTML æ–‡ä»¶æŸ¥çœ‹äº¤äº’å¼å›¾è¡¨")

    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨æ—¶å‡ºé”™: {e}")


def analyze_convergence(study: optuna.Study, window_size: int = 20) -> Dict[str, Any]:
    """åˆ†æä¼˜åŒ–æ”¶æ•›æƒ…å†µ"""
    completed_trials = [
        t
        for t in study.trials
        if t.state == optuna.trial.TrialState.COMPLETE and t.value is not None
    ]

    if len(completed_trials) < window_size:
        return {
            "is_converged": False,
            "reason": f"è¯•éªŒæ•°é‡ä¸è¶³ ({len(completed_trials)} < {window_size})",
            "improvement_rate": 0.0,
        }

    # è®¡ç®—æœ€è¿‘window_sizeä¸ªè¯•éªŒçš„æ”¹è¿›æƒ…å†µ
    recent_trials = completed_trials[-window_size:]
    recent_values = [t.value for t in recent_trials if t.value is not None]

    if not recent_values:
        return {
            "is_converged": False,
            "reason": "æ²¡æœ‰æœ‰æ•ˆçš„è¯•éªŒå€¼",
            "improvement_rate": 0.0,
        }

    # è®¡ç®—æ”¹è¿›ç‡
    best_in_window = max(recent_values)
    all_values = [t.value for t in completed_trials if t.value is not None]
    best_overall = max(all_values) if all_values else 0.0
    improvement_rate = (
        (best_in_window - best_overall) / abs(best_overall) if best_overall != 0 else 0
    )

    # åˆ¤æ–­æ˜¯å¦æ”¶æ•›
    is_converged = abs(improvement_rate) < 0.001  # æ”¹è¿›ç‡å°äº0.1%è®¤ä¸ºæ”¶æ•›

    return {
        "is_converged": is_converged,
        "improvement_rate": improvement_rate,
        "recent_best": best_in_window,
        "overall_best": best_overall,
        "trials_analyzed": len(completed_trials),
    }


def get_n_trials_recommendation(dataset_name: str, algorithm_name: str) -> int:
    """æ ¹æ®æ•°æ®é›†å’Œç®—æ³•æ¨èè¯•éªŒæ¬¡æ•°"""
    # åŸºç¡€è¯•éªŒæ¬¡æ•°
    base_trials = 50

    # æ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´
    dataset_multipliers = {
        "PSM": 2.0,  # å¤§æ•°æ®é›†
        "MSL": 1.5,  # ä¸­ç­‰æ•°æ®é›†
        "CalIt2": 1.0,  # å°æ•°æ®é›†
    }

    # æ ¹æ®ç®—æ³•å¤æ‚åº¦è°ƒæ•´
    algorithm_multipliers = {
        "swift": 1.5,  # å¤æ‚ç®—æ³•ï¼Œéœ€è¦æ›´å¤šè¯•éªŒ
    }

    multiplier = dataset_multipliers.get(dataset_name, 1.0) * algorithm_multipliers.get(
        algorithm_name, 1.0
    )
    recommended_trials = int(base_trials * multiplier)

    return recommended_trials


# ========== ç»Ÿä¸€å‚æ•°é…ç½® ==========
PARAM_CONFIG = {
    "seq_len": {
        "type": "categorical",
        "choices": [64, 128],
        "config_path": "data.seq_len",
    },
    "patch_size": {
        "type": "categorical",
        "choices": [8, 16, 32],
        "config_path": "data.patch_size",
    },
    "patch_stride": {
        "type": "categorical",
        "choices": [4, 8, 16],
        "config_path": "data.patch_stride",
    },
    "d_cf": {
        "type": "categorical",
        "choices": [32, 64, 96],
        "config_path": "model.CFM.d_cf",
    },
    "d_model": {
        "type": "categorical",
        "choices": [64, 96, 128, 256],
        "config_path": "model.CFM.d_model",
    },
    "cfm_num_heads": {
        "type": "categorical",
        "choices": [2, 4],
        "config_path": "model.CFM.num_heads",
    },
    "cfm_attention_dropout": {
        "type": "float",
        "low": 0.1,
        "high": 0.4,
        "config_path": "model.CFM.attention_dropout",
        "decimal_places": 3,
    },
    "cfm_num_layers": {
        "type": "int",
        "low": 2,
        "high": 8,
        "config_path": "model.CFM.num_layers",
    },
    "cfm_dropout": {
        "type": "float",
        "low": 0.1,
        "high": 0.4,
        "config_path": "model.CFM.dropout",
        "decimal_places": 3,
    },
    "cfm_num_gat_heads": {
        "type": "categorical",
        "choices": [2, 4],
        "config_path": "model.CFM.num_gat_heads",
    },
    "cfm_gat_head_dim": {
        "type": "categorical",
        "choices": [8, 16],
        "config_path": "model.CFM.gat_head_dim",
    },
    "fm_level": {
        "type": "int",
        "low": 2,
        "high": 4,
        "config_path": "model.FM.level",
    },
    "fm_wavelet": {
        "type": "categorical",
        "choices": ["db4", "sym4", "coif2"],
        "config_path": "model.FM.wavelet",
    },
    # æ—¶åºé‡æ„å‚æ•°
    "tsrm_is_flatten_individual": {
        "type": "categorical",
        "choices": [True, False],
        "config_path": "model.TSRM.is_flatten_individual",
    },
    # æŸå¤±å‡½æ•°å‚æ•°
    "ccd_loss_lambda": {
        "type": "float",
        "low": 1e-4,
        "high": 1e-1,
        "log": True,
        "config_path": "loss.ccd_loss_lambda",
        "decimal_places": 5,
    },
    "scale_loss_lambda": {
        "type": "float",
        "low": 0.2,
        "high": 1.0,
        "config_path": "loss.scale_loss_lambda",
        "decimal_places": 3,
    },
    "ccd_regular_lambda": {
        "type": "float",
        "low": 0.05,
        "high": 0.5,
        "config_path": "loss.ccd_regular_lambda",
        "decimal_places": 3,
    },
    "ccd_align_lambda": {
        "type": "float",
        "low": 0.5,
        "high": 2.0,
        "config_path": "loss.ccd_align_lambda",
        "decimal_places": 3,
    },
    # è®­ç»ƒå‚æ•°
    "learning_rate": {
        "type": "float",
        "low": 5e-5,
        "high": 1e-2,
        "log": True,
        "config_path": "training.learning_rate",
        "decimal_places": 5,
    },
    "weight_decay": {
        "type": "float",
        "low": 0.0,
        "high": 5e-2,
        "log": False,
        "config_path": "training.weight_decay",
        "decimal_places": 5,
    },
    # å¼‚å¸¸æ£€æµ‹å‚æ•°
    "scale_score_lambda": {
        "type": "float",
        "low": 0.1,
        "high": 1.0,
        "config_path": "anomaly_detection.scale_score_lambda",
        "decimal_places": 3,
    },
    "score_aggregation_alpha": {
        "type": "float",
        "low": 0.1,
        "high": 0.9,
        "config_path": "anomaly_detection.score_aggregation_alpha",
        "decimal_places": 3,
    },
}


def load_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½ toml é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, "rb") as f:
            return tomli.load(f)
    except FileNotFoundError:
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    except Exception as e:
        raise ValueError(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")


def update_config(base_config: Dict[str, Any], param_updates: Dict[str, Any]) -> Dict[str, Any]:
    """æ›´æ–° toml é…ç½®æ–‡ä»¶"""
    config = copy.deepcopy(base_config)
    for key_path, value in param_updates.items():
        # æ”¯æŒä½¿ç”¨è¯¸å¦‚ "model.CFM.d_cf" è¿™æ ·çš„ç‚¹è¯­æ³•æ›´æ–°åµŒå¥—å­—æ®µ
        keys = key_path.split(".")
        current = config
        # ä¾æ¬¡å‘ä¸‹æŸ¥æ‰¾/åˆ›å»ºåµŒå¥—å­—å…¸
        for key in keys[:-1]:
            if key not in current or not isinstance(current[key], dict):
                current[key] = {}
            current = current[key]

        # æ›´æ–°æœ€ç»ˆé”®å¯¹åº”çš„å€¼
        current[keys[-1]] = value
    return config


def save_config(config: Dict[str, Any], output_path: str):
    """ä¿å­˜ toml é…ç½®æ–‡ä»¶"""
    try:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, "wb") as f:
            tomli_w.dump(config, f)
        print(f"ğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")


def suggest_parameter(
    trial: optuna.trial.Trial, param_name: str, param_config: Dict[str, Any]
) -> Any:
    """æ ¹æ®å‚æ•°é…ç½®åŠ¨æ€å»ºè®®å‚æ•°å€¼"""
    param_type = param_config["type"]

    if param_type == "categorical":
        return trial.suggest_categorical(param_name, param_config["choices"])
    elif param_type == "int":
        return trial.suggest_int(param_name, param_config["low"], param_config["high"])
    elif param_type == "float":
        log = param_config.get("log", False)
        value = trial.suggest_float(param_name, param_config["low"], param_config["high"], log=log)
        return value
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å‚æ•°ç±»å‹: {param_type}")


def validate_params(params: Dict[str, Any]) -> bool:
    """éªŒè¯å‚æ•°ç»„åˆçš„æœ‰æ•ˆæ€§"""
    seq_len = params["seq_len"]
    patch_size = params["patch_size"]
    patch_stride = params["patch_stride"]
    d_model = params["d_model"]
    d_cf = params["d_cf"]

    # åŸºæœ¬çº¦æŸæ£€æŸ¥
    if patch_size >= seq_len:
        return False
    if (seq_len - patch_size) % patch_stride != 0:
        return False
    if patch_stride > patch_size:
        return False
    if d_model < d_cf:
        return False

    return True


def objective(
    trial: optuna.trial.Trial,
    base_config: Dict[str, Any],
    all_data: np.ndarray,
    labels: np.ndarray,
    task_name: str,
) -> float:
    """Optunaç›®æ ‡å‡½æ•°"""

    # åœ¨æ¯æ¬¡è¯•éªŒå¼€å§‹å‰æ¸…ç†GPUå†…å­˜
    clear_gpu_memory()

    # åŠ¨æ€ç”Ÿæˆæ‰€æœ‰å‚æ•°
    params = {}
    for param_name, param_config in PARAM_CONFIG.items():
        params[param_name] = suggest_parameter(trial, param_name, param_config)

    # éªŒè¯å‚æ•°ç»„åˆ
    if not validate_params(params):
        raise optuna.TrialPruned("æ— æ•ˆçš„å‚æ•°ç»„åˆ")

    # æ„å»ºå‚æ•°æ›´æ–°å­—å…¸
    param_updates = {}
    for param_name, value in params.items():
        config_path = PARAM_CONFIG[param_name]["config_path"]
        param_updates[config_path] = value

    # æ›´æ–°é…ç½®
    current_config = update_config(base_config, param_updates)
    # è®¾ç½® trial_number ç”¨äºæ—¥å¿—è®°å½•
    current_config["trial_number"] = trial.number

    try:
        if task_name == "find_anomalies":
            # å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ - ä½¿ç”¨ F1 åˆ†æ•°
            predictions = swift_find_anomalies(all_data=all_data, config=current_config)
            result = affiliation_f(labels, predictions)
        elif task_name == "score_anomalies":
            # å¼‚å¸¸è¯„åˆ†ä»»åŠ¡ - ä½¿ç”¨ AUC-ROC
            scores = swift_score_anomalies(all_data=all_data, config=current_config)
            result = auc_roc(labels, scores)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_name}")

        clear_gpu_memory()  # æ¸…ç†å†…å­˜
        return float(result)

    except torch.cuda.OutOfMemoryError as e:
        print(f"ğŸ’¥ Trial {trial.number} GPUå†…å­˜ä¸è¶³: {str(e)[:100]}...")
        clear_gpu_memory()
        raise optuna.TrialPruned(f"GPUå†…å­˜ä¸è¶³: {e}")

    except Exception as e:
        print(f"âŒ Trial {trial.number} æ‰§è¡Œå¤±è´¥: {e}")
        clear_gpu_memory()
        raise optuna.TrialPruned(f"è¯•éªŒæ‰§è¡Œå¤±è´¥: {e}")


def run_optimization(args: argparse.Namespace):
    """è¿è¡Œ Optuna è¶…å‚æ•°ä¼˜åŒ–æµç¨‹"""
    print("ğŸš€ å¼€å§‹è¶…å‚æ•°è°ƒä¼˜...")
    print(f"ğŸ¯ ä»»åŠ¡: {args.task_name} | æ•°æ®é›†: {args.dataset_name} | ç®—æ³•: {args.algorithm_name}")
    print(f"ğŸ”¬ å¼‚å¸¸ç‡: {args.anomaly_ratio}% | è¯•éªŒæ¬¡æ•°: {args.n_trials}")

    # éªŒè¯ä»»åŠ¡ç±»å‹
    if args.task_name not in ["find_anomalies", "score_anomalies"]:
        print(f"âŒ ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {args.task_name}")
        print("ğŸ“ æ”¯æŒçš„ä»»åŠ¡ç±»å‹: find_anomalies, score_anomalies")
        return

    # æ ¹æ®ä»»åŠ¡ç±»å‹ç¡®å®šè¯„ä¼°æŒ‡æ ‡åç§°
    metric_name = "Aff-F" if args.task_name == "find_anomalies" else "A-R"

    # ---------- åŠ è½½åŸºç¡€é…ç½®ä¸æ•°æ® ----------
    try:
        base_config = load_config(args.base_config)
        # å¼‚å¸¸ç‡è®¾ç½®
        base_config["anomaly_detection"]["anomaly_ratio"] = args.anomaly_ratio
        # è®­ç»ƒéªŒè¯é›†é•¿åº¦è®¾ç½®
        base_config["data"]["tain_val_len"] = args.train_val_len

        df = pd.read_csv(args.dataset_path)
        all_data = df.iloc[:, :-1].values  # è®­ç»ƒéªŒè¯æµ‹è¯•é›†
        # æ‰“å°æ•°æ®é›†çš„å½¢çŠ¶
        print(f"æ•°æ®é›†å˜é‡æ•°: {all_data.shape[1]}")
        test_labels = df.iloc[args.train_val_len :, -1].to_numpy()  # æµ‹è¯•é›†æ ‡ç­¾

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    # ---------- åˆ›å»º Optuna Study ----------
    study_db_path = create_study_db_path(args)
    study_name = create_study_name(args)
    print(f"ğŸ’¾ Study DB è·¯å¾„: {study_db_path}")

    # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶é‡å¯
    if args.restart and os.path.exists(study_db_path):
        print("ğŸ”„ å¼ºåˆ¶é‡æ–°å¼€å§‹è°ƒä¼˜ï¼Œåˆ é™¤ç°æœ‰æ•°æ®åº“...")
        try:
            os.remove(study_db_path)
            print(f"ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶: {study_db_path}")
        except Exception as e:
            print(f"âŒ åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
        study = optuna.create_study(
            direction="maximize",
            sampler=optuna.samplers.TPESampler(),
            pruner=optuna.pruners.MedianPruner(),
            storage=f"sqlite:///{study_db_path}",
            study_name=study_name,
            load_if_exists=False,  # å¼ºåˆ¶ä¸åŠ è½½å·²å­˜åœ¨çš„è¯•éªŒ
        )
    else:
        study = optuna.create_study(
            direction="maximize",
            sampler=optuna.samplers.TPESampler(),
            pruner=optuna.pruners.MedianPruner(),
            storage=f"sqlite:///{study_db_path}",
            study_name=study_name,
            load_if_exists=True,
        )

    # æ˜¾ç¤ºå·²å®Œæˆçš„è¯•éªŒä¿¡æ¯
    completed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])
    if completed_trials > 0:
        print(f"ğŸ“Š ä»æ•°æ®åº“æ¢å¤äº† {completed_trials} ä¸ªå·²å®Œæˆçš„è¯•éªŒ")
        try:
            best_trial = study.best_trial
            if best_trial:
                print(f"ğŸ† å½“å‰æœ€ä½³åˆ†æ•°: {best_trial.value:.3f} (Trial {best_trial.number})")
        except ValueError:
            # å½“æ²¡æœ‰å®Œæˆçš„è¯•éªŒæ—¶ï¼Œbest_trial ä¼šæŠ›å‡ºå¼‚å¸¸
            print("âš ï¸ å°šæœªæœ‰å®Œæˆçš„è¯•éªŒ")
    else:
        print("ğŸ†• å¼€å§‹æ–°çš„è°ƒä¼˜ä¼šè¯")

    # è®¡ç®—å‰©ä½™è¯•éªŒæ•°
    remaining_trials = max(0, args.n_trials - len(study.trials))
    if remaining_trials == 0:
        print("âœ… æ‰€æœ‰è¯•éªŒå·²å®Œæˆ!")
        try:
            if study.best_trial:
                print(f"ğŸ† æœ€ä½³åˆ†æ•°: {study.best_trial.value:.3f}")
        except ValueError:
            print("âš ï¸ æ²¡æœ‰å®Œæˆçš„è¯•éªŒ")
        return
    elif remaining_trials < args.n_trials:
        print(f"ğŸ”„ å°†ç»§ç»­æ‰§è¡Œå‰©ä½™çš„ {remaining_trials} ä¸ªè¯•éªŒ")

    # ---------- å›è°ƒç”¨äºè¿½è¸ªæœ€ä½³ç»“æœ ----------
    # ä»æ•°æ®åº“è·å–å½“å‰æœ€ä½³å€¼ï¼Œå®‰å…¨åœ°å¤„ç†æ²¡æœ‰è¯•éªŒçš„æƒ…å†µ
    best_value: float = -1.0
    best_params: Dict[str, Any] = {}
    best_config_path: str = ""  # è®°å½•å½“å‰æœ€ä½³é…ç½®æ–‡ä»¶è·¯å¾„
    try:
        if study.best_trial:
            best_value = study.best_value
            best_params = study.best_params
    except ValueError:
        # æ²¡æœ‰å®Œæˆçš„è¯•éªŒæ—¶ä¼šæŠ›å‡ºå¼‚å¸¸
        pass

    def _callback(study: optuna.Study, trial: optuna.trial.FrozenTrial):
        nonlocal best_value, best_params, best_config_path
        if (
            trial.state == optuna.trial.TrialState.COMPLETE
            and trial.value is not None
            and trial.value > best_value
        ):
            # åˆ é™¤ä¹‹å‰çš„æœ€ä½³é…ç½®æ–‡ä»¶
            if best_config_path and os.path.exists(best_config_path):
                try:
                    os.remove(best_config_path)
                    print(f"ğŸ—‘ï¸ åˆ é™¤ä¹‹å‰çš„é…ç½®: {os.path.basename(best_config_path)}")
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")

            best_value = trial.value
            best_params = trial.params.copy()
            print(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³ç»“æœ: {metric_name} = {best_value:.3f} (Trial {trial.number})")

            param_updates = {}
            for param_name, value in trial.params.items():
                if param_name in PARAM_CONFIG:
                    config_path = PARAM_CONFIG[param_name]["config_path"]
                    # åº”ç”¨ç²¾åº¦å¤„ç†
                    param_config = PARAM_CONFIG[param_name]
                    if param_config["type"] == "float":
                        decimal_places = param_config.get("decimal_places")
                        if decimal_places is not None:
                            value = round(value, decimal_places)
                    param_updates[config_path] = value

            current_best_config = update_config(base_config, param_updates)

            # ç”ŸæˆåŒ…å«æŒ‡æ ‡åˆ†æ•°çš„æ–‡ä»¶å
            base_output_config = args.output_config.replace(".toml", "")
            metric_suffix = "aff-f" if args.task_name == "find_anomalies" else "a-r"
            output_config_with_score = f"{base_output_config}_{metric_suffix}_{best_value:.3f}.toml"
            best_config_path = output_config_with_score  # æ›´æ–°æœ€ä½³é…ç½®è·¯å¾„

            save_config(current_best_config, output_config_with_score)

    # ---------- æ‰§è¡Œä¼˜åŒ– ----------
    try:
        study.optimize(
            lambda t: objective(t, base_config, all_data, test_labels, args.task_name),
            n_trials=remaining_trials,
            callbacks=[_callback],
        )
    except KeyboardInterrupt:
        print("â¹ï¸ ä¼˜åŒ–è¢«ç”¨æˆ·ä¸­æ–­")
        print(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜åˆ°æ•°æ®åº“: {study_db_path}")
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
        print(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜åˆ°æ•°æ®åº“: {study_db_path}")

    # ---------- ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ ----------
    if args.enable_visualization:
        print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        generate_optimization_plots(study, args)
    else:
        print("\nğŸ“Š è·³è¿‡å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆï¼ˆä½¿ç”¨ --enable-visualization å¯ç”¨ï¼‰")

    # ---------- æ”¶æ•›åˆ†æ ----------
    convergence_info = analyze_convergence(study)
    print(f"\nğŸ” æ”¶æ•›åˆ†æ:")
    print(f"  - æ˜¯å¦æ”¶æ•›: {'æ˜¯' if convergence_info['is_converged'] else 'å¦'}")
    if not convergence_info["is_converged"]:
        print(f"  - åŸå› : {convergence_info.get('reason', 'æ”¹è¿›ç‡è¿‡é«˜')}")
    print(f"  - æ”¹è¿›ç‡: {convergence_info['improvement_rate']:.4f}")
    print(f"  - åˆ†æè¯•éªŒæ•°: {convergence_info['trials_analyzed']}")

    # ---------- è¯•éªŒæ¬¡æ•°å»ºè®® ----------
    recommended_trials = get_n_trials_recommendation(args.dataset_name, args.algorithm_name)
    current_trials = len(study.trials)
    if current_trials < recommended_trials:
        print(f"\nğŸ’¡ å»ºè®®: å½“å‰è¯•éªŒæ•° ({current_trials}) å°‘äºæ¨èæ•° ({recommended_trials})")
        print(f"   è€ƒè™‘å¢åŠ è¯•éªŒæ¬¡æ•°ä»¥è·å¾—æ›´å¥½çš„ç»“æœ")

    # ---------- æœ€ç»ˆç»“æœæ€»ç»“ ----------
    try:
        final_best_trial = study.best_trial
        if final_best_trial:
            print("\nâœ… è°ƒä¼˜å®Œæˆ!")
            print(f"ğŸ“Š æœ€ä½³ {metric_name} åˆ†æ•°: {final_best_trial.value:.3f}")
            print(f"ğŸ“ˆ æ€»å…±å®Œæˆäº† {len(study.trials)} ä¸ªè¯•éªŒ")
            print(f"ğŸ’¾ è°ƒä¼˜è¿›åº¦å·²ä¿å­˜åˆ°: {study_db_path}")
        else:
            print("\nâš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æœ€ä½³å‚æ•°ï¼Œè¯·æ£€æŸ¥æ•°æ®å’Œé…ç½®")
    except ValueError:
        # æ²¡æœ‰å®Œæˆçš„è¯•éªŒæ—¶ä¼šæŠ›å‡ºå¼‚å¸¸
        print("\nâš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æœ€ä½³å‚æ•°ï¼Œè¯·æ£€æŸ¥æ•°æ®å’Œé…ç½®")
        if len(study.trials) > 0:
            print(f"ğŸ“ˆ æ€»å…±å°è¯•äº† {len(study.trials)} ä¸ªè¯•éªŒ")
            print(f"ğŸ’¾ è°ƒä¼˜è¿›åº¦å·²ä¿å­˜åˆ°: {study_db_path}")


# --------------------------- CLI ---------------------------
if __name__ == "__main__":
    cli_parser = argparse.ArgumentParser(description="SWIFT è¶…å‚æ•°è°ƒä¼˜å·¥å…·")

    # åŸºæœ¬å‚æ•°
    cli_parser.add_argument("--task-name", type=str, required=True, help="ä»»åŠ¡åç§°")
    cli_parser.add_argument("--dataset-name", type=str, required=True, help="æ•°æ®é›†åç§°")
    cli_parser.add_argument("--train-val-len", type=int, required=True, help="è®­ç»ƒéªŒè¯é›†æ€»é•¿åº¦")
    cli_parser.add_argument("--algorithm-name", type=str, required=True, help="ç®—æ³•åç§°")
    cli_parser.add_argument("--anomaly-ratio", type=float, required=True, help="å¼‚å¸¸ç‡ (ç™¾åˆ†æ¯”)")
    cli_parser.add_argument("--n-trials", type=int, required=True, help="Optuna è¯•éªŒæ¬¡æ•°")

    # è°ƒä¼˜æ§åˆ¶å‚æ•°
    cli_parser.add_argument(
        "--restart", action="store_true", help="å¼ºåˆ¶é‡æ–°å¼€å§‹è°ƒä¼˜ï¼ˆå¿½ç•¥å·²ä¿å­˜çš„è¿›åº¦ï¼‰"
    )
    cli_parser.add_argument(
        "--enable-visualization", action="store_true", help="å¯ç”¨å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆï¼ˆéœ€è¦å®‰è£…plotlyï¼‰"
    )

    # è·¯å¾„å‚æ•°
    cli_parser.add_argument(
        "--base-config",
        type=str,
        default="configs/base/{algorithm_name}.toml",
        help="åŸºç¡€é…ç½®æ–‡ä»¶è·¯å¾„",
    )
    cli_parser.add_argument(
        "--output-config",
        type=str,
        default="configs/{task_name}/{dataset_name}/{algorithm_name}.toml",
        help="è¾“å‡ºé…ç½®æ–‡ä»¶è·¯å¾„",
    )
    cli_parser.add_argument(
        "--dataset-path",
        type=str,
        default="datasets/{dataset_name}.csv",
        help="æ•°æ®é›†æ–‡ä»¶è·¯å¾„",
    )

    _args = cli_parser.parse_args()

    set_seed(1037)  # éšæœºç§å­

    _args.base_config = _args.base_config.format(
        task_name=_args.task_name,
        dataset_name=_args.dataset_name,
        algorithm_name=_args.algorithm_name,
    )
    # å…ˆæ ¼å¼åŒ–åŸºæœ¬ä¿¡æ¯
    _args.output_config = _args.output_config.format(
        task_name=_args.task_name,
        dataset_name=_args.dataset_name,
        algorithm_name=_args.algorithm_name,
    )

    # æ ¹æ®ä»»åŠ¡ç±»å‹å†³å®šæ˜¯å¦æ·»åŠ  ratio å­—æ®µ
    if _args.task_name == "find_anomalies":
        # ä¸º find_anomalies ä»»åŠ¡æ·»åŠ  ratio å­—æ®µ
        base_name = _args.output_config.replace(".toml", "")
        _args.output_config = f"{base_name}_ratio_{_args.anomaly_ratio}.toml"
    _args.dataset_path = _args.dataset_path.format(dataset_name=_args.dataset_name)

    run_optimization(_args)
